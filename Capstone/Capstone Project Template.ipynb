{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project has been created to capture immigrant data arriving at the US entries. The datwarehouse has ETL processing\n",
    "with Spark and Final data will be stored in parquet form on disk.\n",
    "This would enable the end user to read data as required by using processing power of Spark as the final data is stored in a Fact and Dimension creating a Star Schema.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from RawDataProcess import RawDataProcess\n",
    "from DataCleanse import DataCleanse\n",
    "from DataTransform import DataTransform\n",
    "from DataLoader import DataLoader\n",
    "from DataValidation import DataValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "As part of this project, we would look at the immigration data in USA and how Temperature,Race affect the decision for immigrants. Data set used are i94 immigration data coupled with temperature for US cities and demographic data that is available to general public. The output of this project would have Fact and Dimension table that will enable to get the required data in an efficient and confirmed way.\n",
    "Datawarehouse will reside in parquet files that have been created using python ETL scripts and Spark processing power.\n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "***U.S. City Demographic Data (demog):*** Extracted from OpenSoft and includes data by city, state, age, population, veteran status and race.\n",
    "\n",
    "***I94 Immigration Data (sas_data):*** Extracted from the US National Tourism and Trade Office and includes details on incoming immigrants and their ports of entry.\n",
    "\n",
    "***Airport Code Table (airport):*** Extracted from datahub.io and includes airport codes and corresponding cities.\n",
    "\n",
    "***Countries (countries):*** Extracted from I94_SAS_Labels_Descriptions.SAS with country to code mapping\n",
    "\n",
    "***Visas (visa):*** Extracted from I94_SAS_Labels_Descriptions.SAS with visa code to type\n",
    "\n",
    "***Inmigrant Entry Mode (mode):*** Extracted from I94_SAS_Labels_Descriptions.SAS with id maped to Entry mode \n",
    "\n",
    "***Port(Port):*** Extracted from I94_SAS_Labels_Descriptions.SAS with Port mapped to country\n",
    "\n",
    "#### Source Data location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    \"demographics\" : \"./Raw_Data/us-cities-demographics.csv\",\n",
    "    \"airports\" :  \"./Raw_Data/airport-codes_csv.csv\",\n",
    "    \"sas_data\" : \"./sas_data\",\n",
    "    \"us_states\" : \"./Raw_Data/us_states.csv\",\n",
    "    \"cities\" : \"./Raw_Data/cities.csv\",\n",
    "    \"countries\" : \"./Raw_Data/countries.csv\",\n",
    "    \"visa\" : \"./Raw_Data/visa.csv\",\n",
    "    \"ports\" : \"./Raw_Data/port_raw.csv\",\n",
    "    \"mode\" : \"./Raw_Data/mode.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    \"\"\"Creates SparkSession       \n",
    "    Creates SparkSession and returns it. If SparkSession is already created it returns\n",
    "    the currently running SparkSession.    \n",
    "    Input:\n",
    "        None\n",
    "    Returns:\n",
    "        SparkSession\n",
    "    \"\"\"\n",
    "    spark = SparkSession.builder\\\n",
    "                .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "                .enableHiveSupport()\\\n",
    "                .getOrCreate()\n",
    "    return spark\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#creating Clean data for the port data provided in txt file\n",
    "re_obj = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "i94port_valid = {}\n",
    "with open('Raw_Data/portdata_raw.txt') as f:\n",
    "     for line in f:\n",
    "         match = re_obj.search(line)\n",
    "         i94port_valid[match[1]]=[match[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "\n",
    "rawdataprocess = RawDataProcess(spark, paths)\n",
    "\n",
    "dfdemog = rawdataprocess.get_cities_demographics_raw()\n",
    "dfairport=rawdataprocess.get_airports_raw()\n",
    "dfsas_data = rawdataprocess.get_inmigration_raw()\n",
    "dfcountries = rawdataprocess.get_countries_raw()\n",
    "dfvisa = rawdataprocess.get_visa_raw()\n",
    "dfmode = rawdataprocess.get_mode_raw()\n",
    "dfports = rawdataprocess.get_ports_raw()\n",
    "dfusstates = rawdataprocess.get_usstates_raw()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### Review Data in Raw form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|         City|        State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|              Race|Count|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "|Silver Spring|     Maryland|      33.8|          40601|            41862|           82463|              1562|       30908|                   2.6|        MD|Hispanic or Latino|25924|\n",
      "|       Quincy|Massachusetts|      41.0|          44129|            49500|           93629|              4147|       32935|                  2.39|        MA|             White|58723|\n",
      "+-------------+-------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdemog.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "|  00A|     heliport|   Total Rf Heliport|          11|       NA|         US|     US-PA|    Bensalem|     00A|     null|       00A|-74.9336013793945...|\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfairport.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|  State|State_Code|\n",
      "+-------+----------+\n",
      "|Alabama|        AL|\n",
      "| Alaska|        AK|\n",
      "+-------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfusstates.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|    cicid| i94yr|i94mon|i94cit|i94res|i94port|arrdate|i94mode|i94addr|depdate|i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear| dtaddto|gender|insnum|airline|        admnum|fltno|visatype|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "|5748517.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     CA|20582.0|  40.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1976.0|10292016|     F|  null|     QF|9.495387003E10|00011|      B1|\n",
      "|5748518.0|2016.0|   4.0| 245.0| 438.0|    LOS|20574.0|    1.0|     NV|20591.0|  32.0|    1.0|  1.0|20160430|     SYD| null|      G|      O|   null|      M| 1984.0|10292016|     F|  null|     VA|9.495562283E10|00007|      B1|\n",
      "+---------+------+------+------+------+-------+-------+-------+-------+-------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+--------------+-----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfsas_data.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|code|        country_name|\n",
      "+----+--------------------+\n",
      "| 582|MEXICO Air Sea, a...|\n",
      "| 236|         AFGHANISTAN|\n",
      "+----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfcountries.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|visa_id|visa_type|\n",
      "+-------+---------+\n",
      "|      1| Business|\n",
      "|      2| Pleasure|\n",
      "+-------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfvisa.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|cod_id| mode_name|\n",
      "+------+----------+\n",
      "|   1.0|       Air|\n",
      "|   2.0|       Sea|\n",
      "+------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfmode.show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+\n",
      "|code| airport_name|\n",
      "+----+-------------+\n",
      "| ALC|    ALCAN, AK|\n",
      "| ANC|ANCHORAGE, AK|\n",
      "+----+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfports.show(2)\n",
    "#dsplit=dfports[\" airport_name\"].str.split(\",\", n = 1, expand = True)\n",
    "#dsplit = pd.DataFrame(df[\" airport_name\"].str.split(',',1).tolist(), columns = ['a','b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "*Clean countries dataset to get the port code and state code for only USA\n",
    "\n",
    "*Clean demograpihc data for converting string to double for double values and correct column name\n",
    "\n",
    "*Clean ports dataset to get the port code and state code for only USA\n",
    "\n",
    "*Clean airports dataset filtering only US airports and discarding data that is not an airport(\"large_airport\", \"medium_airport\", \"small_airport\"). Extract iso regions and cast fields as required.\n",
    "\n",
    "*Clean the immigration dataset.Standardize date. Mark data that is marked as type invalid in coutry code or ports code with a new column to identif why data set is missing\n",
    "\n",
    "All the data cleansing function has been done with help of a class called DataCleanse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create a tableview for all the data to help with cleaning in next steps.\n",
    "dfdemog.createOrReplaceTempView(\"City\")\n",
    "dfairport.createOrReplaceTempView(\"Airport\")\n",
    "dfsas_data.createOrReplaceTempView(\"Immigration\")\n",
    "dfcountries.createOrReplaceTempView(\"Countries\")\n",
    "dfvisa.createOrReplaceTempView(\"Visa\")\n",
    "dfmode.createOrReplaceTempView(\"Mode\")\n",
    "dfports.createOrReplaceTempView(\"Ports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|state_code|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|        KS|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|        AK|\n",
      "| 00AL|small_airport|        Epps Airpark|         820|       NA|         US|     US-AL|     Harvest|    00AL|     null|      00AL|-86.7703018188476...|        AL|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing cleaning tasks here\n",
    "from DataCleanse import DataCleanse\n",
    "datacleansed=DataCleanse(spark)\n",
    "\n",
    "cl_dfairport=datacleansed.get_airports_cleansed(dfairport)\n",
    "cl_dfairport.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------------+\n",
      "|port_code|        airport_name|port_state_code|\n",
      "+---------+--------------------+---------------+\n",
      "|      ALC|           ALCAN, AK|             AK|\n",
      "|      ANC|       ANCHORAGE, AK|             AK|\n",
      "|      BAR|BAKER AAF - BAKER...|             AK|\n",
      "+---------+--------------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_dfport=datacleansed.get_ports_cleansed(dfports)\n",
    "cl_dfport.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+--------------+\n",
      "|country_code|        country_name|country_status|\n",
      "+------------+--------------------+--------------+\n",
      "|         582|MEXICO Air Sea, a...|         VALID|\n",
      "|         236|         AFGHANISTAN|         VALID|\n",
      "|         101|             ALBANIA|         VALID|\n",
      "|         316|             ALGERIA|         VALID|\n",
      "|         102|             ANDORRA|         VALID|\n",
      "+------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_dfcountries=datacleansed.get_countries_cleansed(dfcountries)\n",
    "cl_dfcountries.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|mode_id|mode_name|\n",
      "+-------+---------+\n",
      "|      1|      Air|\n",
      "|      2|      Sea|\n",
      "|      3|     Land|\n",
      "+-------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_dfmode=datacleansed.get_mode_cleansed(dfmode)\n",
    "cl_dfmode.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "|ident|         type|                name|elevation_ft|continent|iso_country|iso_region|municipality|gps_code|iata_code|local_code|         coordinates|state_code|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "| 00AA|small_airport|Aero B Ranch Airport|        3435|       NA|         US|     US-KS|       Leoti|    00AA|     null|      00AA|-101.473911, 38.7...|        KS|\n",
      "| 00AK|small_airport|        Lowell Field|         450|       NA|         US|     US-AK|Anchor Point|    00AK|     null|      00AK|-151.695999146, 5...|        AK|\n",
      "+-----+-------------+--------------------+------------+---------+-----------+----------+------------+--------+---------+----------+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cl_dfairport=datacleansed.get_airports_cleansed(dfairport)\n",
    "cl_dfairport.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+--------------+----------------+-------+-------+----------+---+----------+-------+-------------+--------------+------+-------+---------+--------+----------+-------+\n",
      "| cic_id|year|month|org_cntry_code|org_country_name|port_id|visa_id|birth_year|age|state_code|mode_id|arrrival_date|departure_date|gender|airline|flight_no|visatype|occupation|counter|\n",
      "+-------+----+-----+--------------+----------------+-------+-------+----------+---+----------+-------+-------------+--------------+------+-------+---------+--------+----------+-------+\n",
      "|5748517|2016|    4|           245|             438|   null|      1|      1976| 40|        CA|      1|   2016-04-30|    2016-05-08|     F|     QF|    00011|      B1|      null|    1.0|\n",
      "|5748518|2016|    4|           245|             438|   null|      1|      1984| 32|        NV|      1|   2016-04-30|    2016-05-17|     F|     VA|    00007|      B1|      null|    1.0|\n",
      "|5748519|2016|    4|           245|             438|   null|      1|      1987| 29|        WA|      1|   2016-04-30|    2016-05-08|     M|     DL|    00040|      B1|      null|    1.0|\n",
      "+-------+----+-----+--------------+----------------+-------+-------+----------+---+----------+-------+-------------+--------------+------+-------+---------+--------+----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_dfimmigration=datacleansed.get_Immigration_cleansed(dfsas_data)\n",
    "cl_dfimmigration.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+------------------+-----+\n",
      "|         City|        State|State_code|Median_age|Male_population|Female_population|Total_population|number_of_veterans|foreign_born|avg_hshld_size|              Race|count|\n",
      "+-------------+-------------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+------------------+-----+\n",
      "|Silver Spring|     Maryland|        MD|      33.8|        40601.0|          41862.0|         82463.0|              1562|       30908|           2.6|Hispanic or Latino|25924|\n",
      "|       Quincy|Massachusetts|        MA|      41.0|        44129.0|          49500.0|         93629.0|              4147|       32935|          2.39|             White|58723|\n",
      "|       Hoover|      Alabama|        AL|      38.5|        38040.0|          46799.0|         84839.0|              4819|        8229|          2.58|             Asian| 4759|\n",
      "+-------------+-------------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+------------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_dfdemographic=datacleansed.get_demo_cleansed(dfdemog)\n",
    "cl_dfdemographic.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "##### we have chosen the Star Schema with fact and dimension to generate our warehouse. Details related to the dimension and fact tables are as below\n",
    "\n",
    "##### Star Schema\n",
    "Dimension Tables:\n",
    "\n",
    "* dim_demographics\n",
    "City,State,State_code,Median_age,Male_population,Female_population,Total_population,number_of_veterans,foreign_born,avg_hshld_size, Race,count ,male_ratio,female_ratio\n",
    "\n",
    "* dim_airports:\n",
    "ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates,state_code\n",
    "\n",
    "* dim_countries:\n",
    "country_code,country_name,country_status\n",
    "\n",
    "* dim_get_visa:\n",
    "visa_id,visa_type\n",
    "\n",
    "* dim_get_mode:\n",
    "mode_id,mode_name\n",
    "\n",
    "* dim_us_states:\n",
    "State,State_Code\n",
    "\n",
    "Fact Table:\n",
    "\n",
    "* immigration_fact_table\n",
    "cic_id,year,month,org_cntry_code,org_country_name,port_id,visa_id,birth_year,age,state_code,mode_id,arrrival_date,departure_date,gender,airline,flight_no,visatype,occupation,counter,\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "* There are two steps:\n",
    "\n",
    "** Tranform data:\n",
    "\n",
    "    1. Transform demographics dataset to inlcude ratio for male and female population\n",
    "    2. Transform inmigration dataset on order to get arrival date in different columns (year, month, day) for partitioning the dataset.\n",
    "    \n",
    "** Generate Model (Star Schema):\n",
    "\n",
    "    1. Create all dimensions in parquet.\n",
    "    2. Create fact table in parquet particioned by year, month, day of th arrival date.\n",
    "    3. Insert in fact table only items with dimension keys right. For integrity and consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+------------------+-----+-------------------+------------------+\n",
      "|         City|        State|State_code|Median_age|Male_population|Female_population|Total_population|number_of_veterans|foreign_born|avg_hshld_size|              Race|count|         male_ratio|      female_ratio|\n",
      "+-------------+-------------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+------------------+-----+-------------------+------------------+\n",
      "|Silver Spring|     Maryland|        MD|      33.8|        40601.0|          41862.0|         82463.0|              1562|       30908|           2.6|Hispanic or Latino|25924|0.49235414670822064|0.5076458532917794|\n",
      "|       Quincy|Massachusetts|        MA|      41.0|        44129.0|          49500.0|         93629.0|              4147|       32935|          2.39|             White|58723|0.47131764731012826|0.5286823526898717|\n",
      "|       Hoover|      Alabama|        AL|      38.5|        38040.0|          46799.0|         84839.0|              4819|        8229|          2.58|             Asian| 4759|  0.448378693761124| 0.551621306238876|\n",
      "+-------------+-------------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+------------------+-----+-------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Performing transformation tasks here\n",
    "#from DataTransform import DataTransform\n",
    "datatransform=DataTransform(spark)\n",
    "\n",
    "tr_dfdemographic=datatransform.get_demo_transform(cl_dfdemographic)\n",
    "tr_dfdemographic.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "paths_write = {\n",
    "    \"demographics\" : \"./model/demographics.parquet\",\n",
    "    \"airports\" :  \"./model/airports.parquet\",\n",
    "    \"ports\" : \"./model/ports.parquet\",\n",
    "    \"countries\" : \"./model/countries.parquet\",\n",
    "    \"visa\" : \"./model/visa.parquet\",\n",
    "    \"mode\" : \"./model/mode.parquet\",\n",
    "    \"facts\" : \"./model/facts_inmigration.parquet\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from DataLoaderc import DataLoader\n",
    "dataloader = DataLoader(spark, paths_write)\n",
    "dataloader.FinalWriter(cl_dfimmigration, cl_dfdemographic, cl_dfairport, dfports, dfcountries, dfvisa, cl_dfmode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "from DataValidation import DataValidation\n",
    "datavalidation=DataValidation(spark, paths_write)\n",
    "\n",
    "facts=datavalidation.get_facts()\n",
    "dim_demographics, dim_airports, dim_ports, dim_countries, dim_get_visa, dim_get_mode = datavalidation.get_dimensions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------+-------+-------+----------+---+----------+-------+-------------+--------------+------+-------+---------+--------+----------+-------+----+-----+-----------+----------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+--------------------+------+-------+---------+-------+---------+\n",
      "| cic_id|org_cntry_code|org_country_name|port_id|visa_id|birth_year|age|state_code|mode_id|arrrival_date|departure_date|gender|airline|flight_no|visatype|occupation|counter|year|month|       City|     State|State_code|Median_age|Male_population|Female_population|Total_population|number_of_veterans|foreign_born|avg_hshld_size|                Race| count|visa_id|visa_type|mode_id|mode_name|\n",
      "+-------+--------------+----------------+-------+-------+----------+---+----------+-------+-------------+--------------+------+-------+---------+--------+----------+-------+----+-----+-----------+----------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+--------------------+------+-------+---------+-------+---------+\n",
      "|5748517|           245|             438|   null|      1|      1976| 40|        CA|      1|   2016-04-30|    2016-05-08|     F|     QF|    00011|      B1|      null|    1.0|2016|    4|   Stockton|California|        CA|      32.5|       150976.0|         154674.0|        305650.0|             12822|       79583|          3.16|American Indian a...| 19834|      1| Business|      1|      Air|\n",
      "|5748517|           245|             438|   null|      1|      1976| 40|        CA|      1|   2016-04-30|    2016-05-08|     F|     QF|    00011|      B1|      null|    1.0|2016|    4|Los Angeles|California|        CA|      35.0|      1958998.0|        2012898.0|       3971896.0|             85417|     1485425|          2.86|Black or African-...|404868|      1| Business|      1|      Air|\n",
      "|5748517|           245|             438|   null|      1|      1976| 40|        CA|      1|   2016-04-30|    2016-05-08|     F|     QF|    00011|      B1|      null|    1.0|2016|    4|      Davis|California|        CA|      26.3|        33493.0|          34163.0|         67656.0|              2176|       13997|          2.69|American Indian a...|   779|      1| Business|      1|      Air|\n",
      "+-------+--------------+----------------+-------+-------+----------+---+----------+-------+-------------+--------------+------+-------+---------+--------+----------+-------+----+-----+-----------+----------+----------+----------+---------------+-----------------+----------------+------------------+------------+--------------+--------------------+------+-------+---------+-------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write code here\n",
    "facts.createOrReplaceTempView(\"immigration\")\n",
    "dim_airports.createOrReplaceTempView(\"airport\")\n",
    "dim_demographics.createOrReplaceTempView(\"demo\")\n",
    "dim_ports.createOrReplaceTempView(\"ports\")\n",
    "dim_countries.createOrReplaceTempView(\"countries\")\n",
    "dim_get_mode.createOrReplaceTempView(\"mode\")\n",
    "dim_get_visa.createOrReplaceTempView(\"visa\")\n",
    "sss=spark.sql(\"\"\"\n",
    "select * from  immigration f join demo dd\n",
    "on f.state_code = dd.state_code\n",
    "join visa on f.visa_id = visa.visa_id \n",
    "join mode on f.mode_id = mode.mode_id\n",
    "\"\"\")\n",
    "sss.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validate all dimensions have data\n",
    "datavalidation.exists_rows(dim_demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datavalidation.exists_rows(dim_airports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datavalidation.exists_rows(dim_ports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datavalidation.exists_rows(dim_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datavalidation.exists_rows(dim_get_visa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datavalidation.exists_rows(dim_get_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datavalidation.exists_rows(facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file.\n",
    "\n",
    "file created - DataDictionary.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people.\n",
    " \n",
    " \n",
    "### Rationale\n",
    "* For the project the scripting language of choice is python as there are are number of libraries available to perform various functions. the data processing is done using Spark as spark can process a huge volume of data and has huge number of library available to support.\n",
    "* The final datawarehouse has been persisted  in parquet files as they can scale upto petabytes of data without any major issues\n",
    "\n",
    "### Dataupdation\n",
    "* propose that the data be updated everyday as we have partioned by month and year and should be easily scalable. and can be traversed without issues. we can use APache airflow to perform this activity.\n",
    "\n",
    "### Different solution\n",
    "* if the data was increased by 100x Spark should be still ale to handle it.\n",
    "* Use Apache airflow  as it has effective SLA, email notificaiton and monitoring capability to help for daily SLA based requirement\n",
    "* Use Hive and spark sql template views for more than 100 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
